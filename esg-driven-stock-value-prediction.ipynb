{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45734ba7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-08-16T15:31:53.119407",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ESG-Driven Stock Value Prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ============ 1. Feature Engineering ============\n",
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates new features from the raw dataframe.\"\"\"\n",
    "    # Composite ESG score\n",
    "    df[\"composite_esg\"] = (df[\"env\"] + df[\"social\"] + df[\"governance\"]) / 3.0\n",
    "    \n",
    "    # Sort by ticker and date to prepare for rolling calculations\n",
    "    df = df.sort_values([\"ticker\", \"date\"])\n",
    "    \n",
    "    # 5-period price momentum (percentage change)\n",
    "    df[\"momentum_5d\"] = df.groupby(\"ticker\")[\"price\"].pct_change(5)\n",
    "    \n",
    "    # 10-period rolling mean price\n",
    "    df[\"rolling_mean_10\"] = df.groupby(\"ticker\")[\"price\"].transform(lambda x: x.rolling(10).mean())\n",
    "    \n",
    "    # Drop rows with NaN values resulting from rolling calculations\n",
    "    df = df.dropna(subset=[\"momentum_5d\", \"rolling_mean_10\", \"composite_esg\"])\n",
    "    return df\n",
    "\n",
    "# ============ 2. Walk-Forward Backtesting ============\n",
    "def _make_class_labels(y_true_block):\n",
    "    \"\"\"\n",
    "    Helper function to create classification labels for a block of price data.\n",
    "    Prices above the median for the block are labeled 1, others are 0.\n",
    "    \"\"\"\n",
    "    median_price = np.median(y_true_block)\n",
    "    return (y_true_block > median_price).astype(int)\n",
    "\n",
    "def walk_forward_backtest(df, features, rf_model, log_model, n_splits=5, target_col=\"price\"):\n",
    "    \"\"\"\n",
    "    Performs a walk-forward backtest and returns detailed performance metrics.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"date\")\n",
    "    dates = df[\"date\"].unique()\n",
    "    split_size = len(dates) // n_splits\n",
    "\n",
    "    # Lists to store results from each fold\n",
    "    rf_rmse_list, log_rmse_list = [], []\n",
    "    rf_acc_list,  log_acc_list  = [], []\n",
    "    fold_labels = []\n",
    "\n",
    "    print(f\"Starting walk-forward backtest with {n_splits} splits...\")\n",
    "    for i in range(n_splits):\n",
    "        # Define the date ranges for training and testing sets\n",
    "        train_dates = dates[: (i + 1) * split_size]\n",
    "        test_dates  = dates[(i + 1) * split_size : (i + 2) * split_size]\n",
    "        \n",
    "        if len(test_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        fold_label = f\"{pd.to_datetime(test_dates[0]).strftime('%Y-%m')} to {pd.to_datetime(test_dates[-1]).strftime('%Y-%m')}\"\n",
    "        fold_labels.append(f\"Fold {i+1}\\n({fold_label})\")\n",
    "        print(f\"  - Fold {i+1}/{n_splits}: Training up to {pd.to_datetime(train_dates[-1]).strftime('%Y-%m')}, Testing on {fold_label}\")\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        train = df[df[\"date\"].isin(train_dates)]\n",
    "        test  = df[df[\"date\"].isin(test_dates)]\n",
    "\n",
    "        X_train, y_train = train[features], train[target_col].values\n",
    "        X_test,  y_test  = test[features],  test[target_col].values\n",
    "\n",
    "        # ---- Random Forest: Regress on price, then convert to classification ----\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_preds_reg = rf_model.predict(X_test)\n",
    "        rf_rmse_list.append(mean_squared_error(y_test, rf_preds_reg, squared=False))\n",
    "\n",
    "        y_test_cls = _make_class_labels(y_test)\n",
    "        rf_preds_cls = (rf_preds_reg > np.median(rf_preds_reg)).astype(int)\n",
    "        rf_acc_list.append(accuracy_score(y_test_cls, rf_preds_cls))\n",
    "\n",
    "        # ---- Logistic Regression: Baseline classification model ----\n",
    "        y_train_cls = _make_class_labels(y_train)\n",
    "        log_model.fit(X_train, y_train_cls)\n",
    "        log_preds_cls = log_model.predict(X_test)\n",
    "        log_acc_list.append(accuracy_score(y_test_cls, log_preds_cls))\n",
    "        \n",
    "        log_probs = log_model.predict_proba(X_test)[:, 1]\n",
    "        log_rmse_list.append(mean_squared_error(y_test, log_probs * np.mean(y_test), squared=False))\n",
    "\n",
    "    results = {\n",
    "        \"rf_rmse\": np.mean(rf_rmse_list), \"log_rmse\": np.mean(log_rmse_list),\n",
    "        \"rf_acc\": np.mean(rf_acc_list), \"log_acc\": np.mean(log_acc_list),\n",
    "        \"lift\": (np.mean(rf_acc_list) - np.mean(log_acc_list)) / np.mean(log_acc_list),\n",
    "        \"rf_acc_folds\": rf_acc_list, \"log_acc_folds\": log_acc_list,\n",
    "        \"fold_labels\": fold_labels\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# ============ 3. Load Existing Data from CSV ============\n",
    "print(\"Loading existing data from CSV file...\")\n",
    "try:\n",
    "    file_path = 'my_esg_stock_data.csv' \n",
    "    df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "    print(f\"Data loaded successfully from {file_path}. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please check the file path and try again.\")\n",
    "    exit() \n",
    "\n",
    "\n",
    "# ============ 4. Full Pipeline ============\n",
    "print(\"Handling missing values...\")\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "print(\"Creating features...\")\n",
    "df = create_features(df)\n",
    "print(f\"Shape after feature engineering: {df.shape}\")\n",
    "\n",
    "# Feature Scaling\n",
    "feature_cols = [c for c in df.columns if c not in [\"date\", \"ticker\", \"price\"]]\n",
    "scaler = StandardScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "# Model Definition\n",
    "rf_model  = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=10)\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Run Walk-Forward Backtest\n",
    "results = walk_forward_backtest(df, feature_cols, rf_model, log_model, n_splits=5)\n",
    "\n",
    "# Print Final Results\n",
    "print(\"\\n\" + \"=\"*25)\n",
    "print(\"=== Backtest Results ===\")\n",
    "print(\"=\"*25)\n",
    "print(f\"Random Forest Avg. RMSE: {results['rf_rmse']:.4f}\")\n",
    "print(f\"Logistic Reg. Avg. RMSE: {results['log_rmse']:.4f}\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Random Forest Avg. Accuracy: {results['rf_acc']:.4f}\")\n",
    "print(f\"Logistic Reg.  Avg. Accuracy: {results['log_acc']:.4f}\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Relative Lift in Classification Accuracy: {results['lift']*100:.2f}%\")\n",
    "print(\"=\"*25 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============ 5. Visualization ============\n",
    "if results and results['fold_labels']:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(results['fold_labels']))\n",
    "\n",
    "    bar1 = plt.bar(index - bar_width/2, results['rf_acc_folds'], bar_width, label='Random Forest', color='royalblue', alpha=0.9)\n",
    "    bar2 = plt.bar(index + bar_width/2, results['log_acc_folds'], bar_width, label='Logistic Regression', color='darkorange', alpha=0.9)\n",
    "\n",
    "    for bar in bar1:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center', fontsize=9)\n",
    "    for bar in bar2:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center', fontsize=9)\n",
    "\n",
    "    plt.xlabel(\"Backtest Fold\", fontsize=12)\n",
    "    plt.ylabel(\"Classification Accuracy\", fontsize=12)\n",
    "    plt.title(\"Model Accuracy Comparison per Fold (Walk-Forward Backtest)\", fontsize=16, fontweight='bold')\n",
    "    plt.xticks(index, results['fold_labels'], rotation=0, ha=\"center\")\n",
    "    if results['rf_acc_folds'] and results['log_acc_folds']:\n",
    "        y_max = max(max(results['rf_acc_folds']), max(results['log_acc_folds'])) * 1.1\n",
    "    else:\n",
    "        y_max = 1.0\n",
    "    plt.ylim(0.45, y_max)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to visualize. This might happen if the dataset is too small for the backtest splits.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-16T15:31:48.108861",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}